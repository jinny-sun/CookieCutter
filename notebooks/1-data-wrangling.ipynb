{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CookieCutter\n",
    "The goal of this project is to predict the calories per serving of a recipe based on the ingredients list.\n",
    "\n",
    "Training data was scraped from AllRecipes.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multireplace(string, replacements, ignore_case=False):\n",
    "    \"\"\"\n",
    "    Given a string and a replacement map, it returns the replaced string.\n",
    "    :param str string: string to execute replacements on\n",
    "    :param dict replacements: replacement dictionary {value to find: value to replace}\n",
    "    :param bool ignore_case: whether the match should be case insensitive\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # If case insensitive, normalize the old string so that later a replacement\n",
    "    # can be found. For instance with {\"HEY\": \"lol\"} we should match and find a replacement for \"hey\",\n",
    "    # \"HEY\", \"hEy\", etc.\n",
    "    \n",
    "    if ignore_case:\n",
    "\n",
    "        def normalize_old(s):\n",
    "            return s.lower()\n",
    "\n",
    "        re_mode = re.IGNORECASE\n",
    "\n",
    "    else:\n",
    "\n",
    "        def normalize_old(s):\n",
    "            return s\n",
    "\n",
    "        re_mode = 0\n",
    "\n",
    "    replacements = {\n",
    "        normalize_old(key): val\n",
    "        for key, val in replacements.items()\n",
    "    }\n",
    "\n",
    "    # Place longer ones first to keep shorter substrings from matching where the longer ones should take place\n",
    "    # For instance given the replacements {'ab': 'AB', 'abc': 'ABC'} against the string 'hey abc', it should produce\n",
    "    # 'hey ABC' and not 'hey ABc'\n",
    "    rep_sorted = sorted(replacements, key=len, reverse=True)\n",
    "    rep_escaped = map(re.escape, rep_sorted)\n",
    "\n",
    "    # Create a big OR regex that matches any of the substrings to replace\n",
    "    pattern = re.compile(\"|\".join(rep_escaped), re_mode)\n",
    "\n",
    "    # For each match, look up the new string in the replacements, being the key the normalized old string\n",
    "    return pattern.sub(\n",
    "        lambda match: replacements[normalize_old(match.group(0))], string)\n",
    "\n",
    "\n",
    "def string_replace(orig_string):\n",
    "    \"\"\"\n",
    "    Replace whitespace characters with semicolon\n",
    "    \"\"\"\n",
    "    new_string = re.sub(' {2,}', ' ', orig_string).replace(\"\\n\", \";\").replace(\"; ;\", \";\")\n",
    "    return (new_string)\n",
    "\n",
    "\n",
    "def get_ingredients(orig_string):\n",
    "    \"\"\"\n",
    "    Separate numeric and text characters in a string\n",
    "    \"\"\"\n",
    "    ing_regex = ('(\\d+/*\\d*\\s*\\d*/*\\d*)\\s(\\w+\\s*.*?);')\n",
    "    all_ing = re.findall(ing_regex, orig_string)\n",
    "    return (all_ing)\n",
    "\n",
    "\n",
    "def get_quantity(regex_tuple):\n",
    "    \"\"\"\n",
    "    Separate tupule into two columns\n",
    "    \"\"\"\n",
    "    quantity = [y[0] for y in regex_tuple]\n",
    "    units_with_ingredient = [y[1] for y in regex_tuple]\n",
    "    df_of_units = pd.DataFrame({\n",
    "        'quantity': quantity,\n",
    "        'ingredient': units_with_ingredient\n",
    "    })\n",
    "    return (df_of_units)\n",
    "\n",
    "\n",
    "def match_uids(originaldf, longdf):\n",
    "    \"\"\"\n",
    "    Merge two dataframs using unique identifier\n",
    "    \"\"\"\n",
    "    for row in range(0, len(originaldf)):\n",
    "        longdf[row]['recipe_key'] = originaldf['recipe_key'][row]\n",
    "        longdf[row]['calPerServing'] = originaldf['calPerServing'][row]\n",
    "        longdf[row]['totalCal'] = originaldf['totalCal'][row]\n",
    "        longdf[row]['servings'] = originaldf['servings'][row]\n",
    "        longdf[row]['name'] = originaldf['name'][row]\n",
    "    return (longdf)\n",
    "\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove anything in parentheses\n",
    "    2. Lowercase all text\n",
    "    3. Remove all hypenated words\n",
    "    4. Remove all punctuation\n",
    "    5. Remove all whitespace\n",
    "    6. Remove numbers\n",
    "    7. Remove plurals\n",
    "    8. Remove all english stopwords & unwanted text\n",
    "    9. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    def lemmatize(string):\n",
    "        for word in re.findall(r\"[a-z]+\", string):\n",
    "            string = string.replace(\n",
    "                word,\n",
    "                wnl.lemmatize(word, 'n') if 's' in word[-3:] else word)\n",
    "        return string\n",
    "\n",
    "    unwanted_text = [\n",
    "        'dash', 'pinch', 'teaspoon', 'tablespoon', 'fluid', 'cup', 'pint',\n",
    "        'quart', 'ounce', 'oz', 'pound', 'rack', 'small', 'medium', 'large',\n",
    "        'crushed', 'grated', 'skinless', 'boneless', 'melted', 'fresh',\n",
    "        'diced', 'minced', 'thinly', 'dry', 'dried', 'halved', 'taste',\n",
    "        'frying', 'lean', 'drained', 'jars', 'grated', 'clove', 'slice',\n",
    "        'eaches', 'whole', 'cube', 'thick', 'unit', 'freshly', 'finely',\n",
    "        'splash', 'semisweet', 'chip', 'extract', 'spread', 'powder', 'room',\n",
    "        'temperature', 'brown', 'cooking', 'yolk', 'ground', 'package', 'mix',\n",
    "        'cake', 'plain', 'goody', 'light', 'wheat', 'piece', 'substitute',\n",
    "        'mini', 'kosher', 'crispy', 'minature', 'chunk', 'dark', 'bit',\n",
    "        'square', 'boiling', 'bag', 'crumb', 'popsicle', 'stick', 'zest',\n",
    "        'cereal', 'bar', 'tart', 'nib', 'tennessee', 'turbinado', 'baking',\n",
    "        'pack', 'spice', 'moist', 'miniarature', 'crunchy', 'morsel', 'nugget',\n",
    "        'candy', 'crisp', 'super', 'fine', 'decoration', 'sucralose', 'puree',\n",
    "        'pureed', 'rainbow', 'cut', 'frozen', 'broken', 'round', 'concentrate',\n",
    "        'miniature', 'cooky', 'virgin', 'dusting', 'half', 'baby', 'food',\n",
    "        'jar', 'seedless', 'container', 'box', 'granule', 'filling', 'cold',\n",
    "        'super', 'ripe', 'moisture', 'packet', 'instant', 'mint', 'ripe',\n",
    "        'sea', 'coarse', 'fun', 'size', 'funsize', 'bulk', 'chopped', 'torn',\n",
    "        'inch', 'shell', 'quality', 'strap', 'bittersweet', 'gallon', 'pure',\n",
    "        'cane', 'liquid', 'drop', 'hard', 'yellow', 'black', 'strap', 'kiss',\n",
    "        'protein', 'supplement', 'dessert', 'topping'\n",
    "    ]\n",
    "\n",
    "    # Remove anything in parenthesis\n",
    "    mess = re.sub(r\"\\([^\\)]+\\)\", '', mess)\n",
    "    # Make everything lowercase\n",
    "    mess = mess.lower()\n",
    "    # Remove non-word punctuation\n",
    "    mess = ' '.join(re.findall(\n",
    "        r\"[-,''\\w]+\", mess))  # This leaves some commas as a character #\n",
    "    mess = re.sub(r\"\\,\", ' ', mess)\n",
    "    # Remove hypenated words\n",
    "    mess = re.sub(r\"(?=\\S*['-])([a-zA-Z'-]+)\", '',\n",
    "                  mess)  # remove hypenated words\n",
    "    # Remove numbers\n",
    "    mess = ''.join([i for i in mess if not i.isdigit()])\n",
    "    # Remove plurals\n",
    "    mess = lemmatize(mess)\n",
    "    #clean excess whitespace\n",
    "    mess = re.sub(r\"\\s+\", ' ', mess).strip()\n",
    "    # Remove stopwords\n",
    "    mess = [\n",
    "        word for word in mess.split()\n",
    "        if word.lower() not in stopwords.words('english')\n",
    "    ]\n",
    "    mess = [word for word in mess if word.lower() not in unwanted_text]\n",
    "    mess = ' '.join(mess)\n",
    "    return (mess.split())\n",
    "\n",
    "\n",
    "def convert_fractions(quantity):\n",
    "    \"\"\"\n",
    "    Convert fractions into decimals\n",
    "    \"\"\"\n",
    "    from fractions import Fraction\n",
    "    return float(sum(Fraction(s) for s in quantity.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean ingredient text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('cookie_recipes.csv') # all cookie recipes\n",
    "\n",
    "# Create unique id\n",
    "df['recipe_key'] = df['url'].apply(lambda x:int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "# Calculate total calories per recipe\n",
    "df['totalCal'] = df['calPerServing']*df['servings']\n",
    "\n",
    "# Filter for recipes with 12-64 servings and < 10,000 total calories\n",
    "df = df[(df['servings']<=64) & \n",
    "        (df['servings']>=12) & \n",
    "        (df['totalCal']<10000)] \n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Clean ingredient text\n",
    "dict_unicode = {'\\u2009': '', '½':' 1/2', '⅓':'1/3', '⅔':'2/3', '¼':'1/4', '¾':'3/4', '⅕':'1/5', \n",
    "                '⅖':'2/5', '⅗':'3/5', '⅘':'4/5', '⅙':'1/6', '⅚':'5/6', '⅐':'1/7', '⅛':'1/8', \n",
    "                '⅜':'3/8', '⅝':'5/8', '⅞':'7/8', '⅑':'1/9', '⅒':'1/10'}\n",
    "df['ingredients'] = [item + ';' for item in df['ingredients']] # add semicolon at end of each string for easier regex filtering\n",
    "df['ingredients'] = [multireplace(x, dict_unicode) for x in df['ingredients']] # replace unicode characters\n",
    "df['ingredients'] = [string_replace(x) for x in df['ingredients']] # remove whitespace\n",
    "ing = [get_ingredients(x) for x in df['ingredients']] # separate ingredients into list of list of tupules of ingredient strings\n",
    "\n",
    "# Separate quantity from ingredient string\n",
    "df_ing = [get_quantity(x) for x in ing]\n",
    "\n",
    "clean_df = match_uids(df, df_ing) # pull unique id, calorie (outcome variable), number of servings, and number of ingredients from original dataframe\n",
    "clean_df = pd.concat(clean_df) # concat list of pandas dataframes into one dataframe\n",
    "clean_df['quantity'] = [convert_fractions(x) for x in clean_df['quantity']] # convert fractions into integers\n",
    "clean_df = clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True # Plot edges on bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df['calPerServing'].plot(kind='hist',ylim=(0,500),bins=20)\n",
    "ax.set_xlabel('Calories per Serving')\n",
    "ax.set_ylabel('Number of Recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(clean_df['totalCal'],kde=False,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(x='servings', y='calPerServing', data=clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
